{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.4 64-bit (conda)",
   "display_name": "Python 3.7.4 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "7a6d91089636ceb79144559d125f13240294e23fe1ab18b5e7078f2814f8930e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(dta):\n",
    "    dta['Date'] = pd.to_datetime(dta['Date'], format='%Y-%m-%d')\n",
    "    dta = dta.set_index(dta['Date'])\n",
    "    # NHLI not traded\n",
    "    dta.drop(['Date', 'NHLI'], axis=1, inplace=True)\n",
    "    dta.dropna(how='all', inplace=True)\n",
    "    for tick in dta.columns:\n",
    "        tick_series = dta[tick]\n",
    "        start_pos = tick_series.first_valid_index()\n",
    "        valid_series = tick_series.loc[start_pos:]\n",
    "        if valid_series.isna().sum() > 0:\n",
    "            dta.drop(tick, axis=1, inplace=True)\n",
    "\n",
    "    for tick in dta.columns:\n",
    "        dta[tick] = dta[tick].mask(dta[tick] == 0).ffill(downcast='infer')\n",
    "\n",
    "    return dta[dta.index >= dta['SPY'].first_valid_index()]\n",
    "\n",
    "\n",
    "def coint_group(tick, dta):\n",
    "    \"\"\"\n",
    "    Use cointegration test and correlation to find predictive stocks for target\n",
    "    :param tick: string for the target stock\n",
    "    :param dta: the data file (csv) that contains the tick\n",
    "    :return: a list of tickers that are in sp500 which predict the target\n",
    "    \"\"\"\n",
    "    y = dta['%s_LAG' % tick]\n",
    "    cointegrat = {}\n",
    "    correlat = {}\n",
    "\n",
    "    for i in dta.columns[:-2]:\n",
    "        x = dta[i]\n",
    "        score, pval, _ = coint(x, y, trend='ct')\n",
    "        corr = x.corr(y)\n",
    "\n",
    "        cointegrat[i] = pval\n",
    "        correlat[i] = corr\n",
    "\n",
    "    best_coint = sorted(cointegrat, key=cointegrat.get)[:50]\n",
    "    best_corr = sorted(correlat, key=correlat.get, reverse=True)[:50]\n",
    "\n",
    "    intersect = list(set(best_coint) & set(best_corr))\n",
    "    if len(intersect) > 0:\n",
    "        print(\"There are {} cointegrated stocks.\".format(len(intersect)))\n",
    "        return intersect\n",
    "    else:\n",
    "        print(\"Intersection is empty.\")\n",
    "        return best_coint[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = ['Regression_Prediction_%s.csv' % i for i in range(1,4)]\n",
    "\n",
    "dta_list = []\n",
    "for file in file_name:\n",
    "    dta = pd.read_csv(file)\n",
    "    dta_list.append(dta)\n",
    "\n",
    "ttl = pd.concat(dta_list, axis=0)\n",
    "\n",
    "ttl.to_csv(\"Prediction Result/temp1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = ttl[(ttl['NetProfit'] > 0) & (ttl['GrossProfit'] > 0) & ttl['Var'] > 0]\n",
    "filter2 = filter1[(filter1.L1_MSE <= 0.02) & (filter1.L2_MSE <= 0.02) & (filter1.OLS_MSE <= 0.02)]\n",
    "filter3 = filter2[filter2.NetProfit > filter2.GrossProfit]\n",
    "\n",
    "filter3['Sharpe_2'] = filter3.GrossProfit / filter3.Var\n",
    "filter3['SP_ttl'] = filter3.Sharpe + filter3.Sharpe_2\n",
    "target_list = filter3.sort_values(['SP_ttl'], ascending=False).iloc[:10]['Unnamed: 0'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('broader_stock.csv')\n",
    "data = data_preprocess(data)\n",
    "\n",
    "result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 6 cointegrated stocks.\n",
      "There are 7 cointegrated stocks.\n",
      "There are 15 cointegrated stocks.\n",
      "There are 7 cointegrated stocks.\n",
      "There are 17 cointegrated stocks.\n",
      "There are 9 cointegrated stocks.\n",
      "There are 6 cointegrated stocks.\n",
      "There are 13 cointegrated stocks.\n",
      "There are 9 cointegrated stocks.\n",
      "There are 11 cointegrated stocks.\n"
     ]
    }
   ],
   "source": [
    "for tick in target_list:\n",
    "    original_series = data[tick]\n",
    "\n",
    "    if tick in data.columns:\n",
    "        original_data = pd.concat([data.drop([tick], axis=1), original_series], axis=1)\n",
    "        original_data = original_data[original_data[tick].notnull()].dropna(axis=1)\n",
    "    else:\n",
    "        original_data = pd.concat([data, original_series], axis=1)\n",
    "        original_data = original_data[original_data[tick].notnull()].dropna(axis=1)\n",
    "\n",
    "    if original_data.index[-1] != data.index[-1]:\n",
    "        continue\n",
    "\n",
    "    original_data['%s_LAG' % tick] = original_data[tick].shift(-120)\n",
    "    model_data = original_data.dropna()\n",
    "\n",
    "    arr = model_data[tick]\n",
    "\n",
    "    coint_corr = coint_group(tick, model_data)\n",
    "    result[tick] = coint_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = json.dumps(result)\n",
    "f = open(\"Prediction Result/dict.json\", \"w\")\n",
    "f.write(json_file)\n",
    "f.close()"
   ]
  },
  {
   "source": [
    "# Actual Directional Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {1:'a',2:'b',-1:'c'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "np.argmin(list(test.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "list(test.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Prediction Result/dict.json\") as json_file:\n",
    "    result = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('broader_stock.csv')\n",
    "data = data_preprocess(data)\n",
    "\n",
    "alphas = np.linspace(0.001, 1000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl = pd.read_csv(\"Prediction Result/temp1.csv\")\n",
    "ttl.set_index(['Unnamed: 0.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_prediction = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-08c690a41b27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmodel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mttl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'L1_MSE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'L2_MSE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'OLS_MSE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "for key in result:\n",
    "    model_type = np.argmin(ttl.loc[key][['L1_MSE', 'L2_MSE', 'OLS_MSE']])\n",
    "    y = data[key].shift(-120).dropna().values\n",
    "    n = y.shape[0]\n",
    "    x = data[result[key]].iloc[-n-120:-120].values\n",
    "    x_test = data[result[key]].iloc[-1].values\n",
    "    if model_type == 0:\n",
    "        model = LassoCV(alphas=alphas, max_iter=5000, fit_intercept=True, cv=10, n_jobs=-1).fit(x, y)\n",
    "        pred = model.predict(x_test.reshape(1,-1))\n",
    "    elif model_type == 1:\n",
    "        model = RidgeCV(alphas=alphas, fit_intercept=True, cv=10).fit(x, y)\n",
    "        pred = model.predict(x_test.reshape(1,-1))\n",
    "    elif model_type == 2:\n",
    "        model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "        pred = model.predict(sm.add_constant(x_test))\n",
    "    \n",
    "    trade_prediction[key] = pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'BHE': 25.935497641926574,\n",
       " 'MSTR': 178.064517178035,\n",
       " 'FCF': 8.019808447394992,\n",
       " 'KAMN': 52.28936159046932,\n",
       " 'STBA': 26.434043804371317,\n",
       " 'BMY': 67.38971115600006,\n",
       " 'POST': 142.50049475081406,\n",
       " 'VLY': 8.06837320105426,\n",
       " 'SWX': 73.23632871815617,\n",
       " 'AIV': 39.56509122636441}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "trade_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}