{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('images_npy/C_x.npy')\n",
    "Y = np.load('images_npy/C_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(X[:,:,5050])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Machine Learning Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import torch\n",
    "from torch.nn import Linear, ReLU, Conv1d, Conv2d, Flatten, Sequential, CrossEntropyLoss, MSELoss, MaxPool1d, MaxPool2d, Dropout, BatchNorm1d, BatchNorm2d\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding = (self.kernel_size[0] // 2, self.kernel_size[1] // 2)\n",
    "        \n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "conv = conv3x3(in_channels=32, out_channels=64)\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_func(activation):\n",
    "    return nn.ModuleDict([\n",
    "        ['relu', nn.ReLU(inplace=True)],\n",
    "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
    "        ['selu', nn.SELU(inplace=True)],\n",
    "        ['none', nn.Identity()]\n",
    "    ])[activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
    "        self.blocks = nn.Identity()\n",
    "        self.activate = activation_func(activation)\n",
    "        self.shortcut = nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        x = self.activate(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1, stride=self.downsampling, bias=False),\n",
    "            nn.BatchNorm2d(self.expanded_channels)) if self.should_apply_shortcut else None\n",
    "    \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetResidualBlock(\n",
       "  (blocks): Identity()\n",
       "  (activate): ReLU(inplace=True)\n",
       "  (shortcut): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNetResidualBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs),\n",
    "                        nn.BatchNorm2d(out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 10, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.ones((1,32, 10, 10))\n",
    "\n",
    "block = ResNetBasicBlock(32, 64)\n",
    "block(dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetBasicBlock(\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (activate): ReLU(inplace=True)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBottleNeckBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels, out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels * block.expansion,\n",
    "                   out_channels, downsampling=1, *args, **kwargs) for _ in range(n-1)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 24, 24])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.ones((1,64, 48,48))\n",
    "\n",
    "layer = ResNetLayer(64, 128, block=ResNetBottleNeckBlock, n=1)\n",
    "layer(dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[1, 1, 1, 1], activation='relu',\n",
    "                 block=ResNetBottleNeckBlock, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block_sizes = blocks_sizes\n",
    "\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.block_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.block_sizes[0]),\n",
    "            activation_func(activation),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, block=block, *args,\n",
    "                        **kwargs),\n",
    "            *[ResNetLayer(in_channels * block.expansion, out_channels, n=n, activation=activation, block=block, *args,\n",
    "                          **kwargs)\n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])\n",
    "              ]\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetDecoder(nn.Module):\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.decoder = nn.ModuleList([\n",
    "            nn.Linear(in_features, 500),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(500, 100),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(100, 25)\n",
    "        ])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for block in self.decoder:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
    "        self.decoder = ResNetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_conv1(in_channels, n_classes, block=ResNetBottleNeckBlock, *args, **kwargs):\n",
    "    return ResNet(in_channels, n_classes, block=block, deepths=[1,1,1,1], *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res_conv1(3, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ResNetEncoder: 1-1                     [-1, 2048, 2, 2]          --\n",
      "|    └─Sequential: 2-1                   [-1, 64, 16, 16]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 32, 32]          9,408\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 32, 32]          128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 32, 32]          --\n",
      "|    |    └─MaxPool2d: 3-4               [-1, 64, 16, 16]          --\n",
      "├─ResNetDecoder: 1-2                     [-1, 25]                  --\n",
      "|    └─AdaptiveAvgPool2d: 2-2            [-1, 2048, 1, 1]          --\n",
      "==========================================================================================\n",
      "Total params: 9,093,061\n",
      "Trainable params: 9,093,061\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.00\n",
      "Params size (MB): 34.69\n",
      "Estimated Total Size (MB): 35.74\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------------------------------------\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─ResNetEncoder: 1-1                     [-1, 2048, 2, 2]          --\n",
       "|    └─Sequential: 2-1                   [-1, 64, 16, 16]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 32, 32]          9,408\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 32, 32]          128\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 32, 32]          --\n",
       "|    |    └─MaxPool2d: 3-4               [-1, 64, 16, 16]          --\n",
       "├─ResNetDecoder: 1-2                     [-1, 25]                  --\n",
       "|    └─AdaptiveAvgPool2d: 2-2            [-1, 2048, 1, 1]          --\n",
       "==========================================================================================\n",
       "Total params: 9,093,061\n",
       "Trainable params: 9,093,061\n",
       "Non-trainable params: 0\n",
       "------------------------------------------------------------------------------------------\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 1.00\n",
       "Params size (MB): 34.69\n",
       "Estimated Total Size (MB): 35.74\n",
       "------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.cuda(), (3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ResNet(\n",
       "   (encoder): ResNetEncoder(\n",
       "     (gate): Sequential(\n",
       "       (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "       (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "       (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (blocks): ModuleList(\n",
       "       (0): ResNetLayer(\n",
       "         (blocks): Sequential(\n",
       "           (0): ResNetBottleNeckBlock(\n",
       "             (blocks): Sequential(\n",
       "               (0): Sequential(\n",
       "                 (0): Conv2dAuto(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "               (1): ReLU(inplace=True)\n",
       "               (2): Sequential(\n",
       "                 (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "               (3): ReLU(inplace=True)\n",
       "               (4): Sequential(\n",
       "                 (0): Conv2dAuto(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (activate): ReLU(inplace=True)\n",
       "             (shortcut): Sequential(\n",
       "               (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "               (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ResNetLayer(\n",
       "         (blocks): Sequential(\n",
       "           (0): ResNetBottleNeckBlock(\n",
       "             (blocks): Sequential(\n",
       "               (0): Sequential(\n",
       "                 (0): Conv2dAuto(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "               (1): ReLU(inplace=True)\n",
       "               (2): Sequential(\n",
       "                 (0): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "               (3): ReLU(inplace=True)\n",
       "               (4): Sequential(\n",
       "                 (0): Conv2dAuto(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (activate): ReLU(inplace=True)\n",
       "             (shortcut): Sequential(\n",
       "               (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): ResNetLayer(\n",
       "         (blocks): Sequential(\n",
       "           (0): ResNetBottleNeckBlock(\n",
       "             (blocks): Sequential(\n",
       "               (0): Sequential(\n",
       "                 (0): Conv2dAuto(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "               (1): ReLU(inplace=True)\n",
       "               (2): Sequential(\n",
       "                 (0): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "               (3): ReLU(inplace=True)\n",
       "               (4): Sequential(\n",
       "                 (0): Conv2dAuto(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (activate): ReLU(inplace=True)\n",
       "             (shortcut): Sequential(\n",
       "               (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (3): ResNetLayer(\n",
       "         (blocks): Sequential(\n",
       "           (0): ResNetBottleNeckBlock(\n",
       "             (blocks): Sequential(\n",
       "               (0): Sequential(\n",
       "                 (0): Conv2dAuto(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "               (1): ReLU(inplace=True)\n",
       "               (2): Sequential(\n",
       "                 (0): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "               (3): ReLU(inplace=True)\n",
       "               (4): Sequential(\n",
       "                 (0): Conv2dAuto(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                 (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (activate): ReLU(inplace=True)\n",
       "             (shortcut): Sequential(\n",
       "               (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "               (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (decoder): ResNetDecoder(\n",
       "     (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "     (decoder): ModuleList(\n",
       "       (0): Linear(in_features=2048, out_features=500, bias=True)\n",
       "       (1): Dropout2d(p=0.5, inplace=False)\n",
       "       (2): Linear(in_features=500, out_features=100, bias=True)\n",
       "       (3): Dropout2d(p=0.5, inplace=False)\n",
       "       (4): Linear(in_features=100, out_features=25, bias=True)\n",
       "     )\n",
       "   )\n",
       " ), (3, 64, 64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(), (3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 700, 10134)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
