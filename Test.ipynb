{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dta_to_candlestick(data):\n",
    "    l = len(data)\n",
    "    # Make candlestick picture\n",
    "    layout = go.Layout(xaxis=dict(ticks='',\n",
    "                                  showgrid=False,\n",
    "                                  showticklabels=False,\n",
    "                                  rangeslider=dict(visible=False)),\n",
    "                       yaxis=dict(ticks='',\n",
    "                                  showgrid=False,\n",
    "                                  showticklabels=False),\n",
    "                       width=500,\n",
    "                       height=500,\n",
    "                       paper_bgcolor='rgba(0,0,0,0)',\n",
    "                       plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig = go.Figure(data=[go.Candlestick(x=np.linspace(1,l,l),\n",
    "                                         open=data.Open,\n",
    "                                         high=data.High,\n",
    "                                         low=data.Low,\n",
    "                                         close=data.Close)],\n",
    "                    layout=layout)\n",
    "    fig.write_image(\"images/fig-53.png\")\n",
    "\n",
    "    # Convert to numpy array\n",
    "    im = Image.open('images/fig-53.png')\n",
    "    #im = im.resize((300,300),Image.ANTIALIAS)\n",
    "    data = np.asarray(im)\n",
    "\n",
    "    # Return the first channel of the image\n",
    "    return data[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = datetime(1980, 1, 1)\n",
    "END = datetime(2020, 4, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = yf.Ticker('MSFT')\n",
    "hist = tic.history(start=START, end=END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dta_transformation(data, est_h):\n",
    "    # Make sure data has sufficient columns\n",
    "    assert 'Open' in data.columns\n",
    "    assert 'High' in data.columns\n",
    "    assert 'Low' in data.columns\n",
    "    assert 'Close' in data.columns\n",
    "\n",
    "    data['lag_close'] = data['Close'].shift(1)\n",
    "    data['Indicator'] = np.where(data['Close'] > data['lag_close'], 1, 0)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(est_h, data.shape[0]):\n",
    "        sub_dta = data.iloc[i - est_h:i]\n",
    "\n",
    "        y_i = data.iloc[i]['Indicator']\n",
    "        x_i = dta_to_candlestick(sub_dta)\n",
    "\n",
    "        y.append(y_i)\n",
    "        x.append(x_i)\n",
    "\n",
    "        print(\"{}/{}\".format(i - est_h, data.shape[0] - est_h))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andyy\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Andyy\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10\n",
      "1/10\n",
      "2/10\n",
      "3/10\n",
      "4/10\n",
      "5/10\n",
      "6/10\n",
      "7/10\n",
      "8/10\n",
      "9/10\n"
     ]
    }
   ],
   "source": [
    "x, y = dta_transformation(hist.iloc[1000:1040], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.stack(x, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(x[:,:,0])\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_x = x[:,:,568:1568]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8568,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_y = y[568:1568]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('test_1', x=sub_x, y=sub_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[2] // 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    sub_x = x[:,:,(1000*i+568):(1000*(i+1)+568)]\n",
    "    sub_y = y[(1000*i+568):(1000*(i+1)+568)]\n",
    "    np.savez_compressed('test_{}'.format(i), x=sub_x, y=sub_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333.7860107421875"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "350000000/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2998800000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load('test_0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_x = loaded['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 700, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta_y = loaded['y']\n",
    "dta_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Machine Learning Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet_CNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import torch\n",
    "from torch.nn import Linear, ReLU, Conv1d, Conv2d, Flatten, Sequential, CrossEntropyLoss, MSELoss, MaxPool1d, MaxPool2d, Dropout, BatchNorm1d, BatchNorm2d\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res_conv1(1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (gate): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): ResNetLayer(\n",
      "        (blocks): Sequential(\n",
      "          (0): ResNetBottleNeckBlock(\n",
      "            (blocks): Sequential(\n",
      "              (0): Sequential(\n",
      "                (0): Conv2dAuto(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Sequential(\n",
      "                (0): Conv2dAuto(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (3): ReLU(inplace=True)\n",
      "              (4): Sequential(\n",
      "                (0): Conv2dAuto(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (activate): ReLU(inplace=True)\n",
      "            (shortcut): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): ResNetLayer(\n",
      "        (blocks): Sequential(\n",
      "          (0): ResNetBottleNeckBlock(\n",
      "            (blocks): Sequential(\n",
      "              (0): Sequential(\n",
      "                (0): Conv2dAuto(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Sequential(\n",
      "                (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (3): ReLU(inplace=True)\n",
      "              (4): Sequential(\n",
      "                (0): Conv2dAuto(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (activate): ReLU(inplace=True)\n",
      "            (shortcut): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): ResNetLayer(\n",
      "        (blocks): Sequential(\n",
      "          (0): ResNetBottleNeckBlock(\n",
      "            (blocks): Sequential(\n",
      "              (0): Sequential(\n",
      "                (0): Conv2dAuto(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Sequential(\n",
      "                (0): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (3): ReLU(inplace=True)\n",
      "              (4): Sequential(\n",
      "                (0): Conv2dAuto(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (activate): ReLU(inplace=True)\n",
      "            (shortcut): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ResNetDecoder(\n",
      "    (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (decoder): ModuleList(\n",
      "      (0): Linear(in_features=512, out_features=100, bias=True)\n",
      "      (1): Dropout2d(p=0.5, inplace=False)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=100, out_features=25, bias=True)\n",
      "      (4): Dropout2d(p=0.5, inplace=False)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=25, out_features=1, bias=True)\n",
      "      (7): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ResNetEncoder: 1-1                     [-1, 512, 32, 32]         --\n",
      "|    └─Sequential: 2-1                   [-1, 32, 125, 125]        --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 32, 250, 250]        1,568\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 32, 250, 250]        64\n",
      "|    |    └─ReLU: 3-3                    [-1, 32, 250, 250]        --\n",
      "|    |    └─MaxPool2d: 3-4               [-1, 32, 125, 125]        --\n",
      "├─ResNetDecoder: 1-2                     [-1, 1]                   --\n",
      "|    └─AdaptiveAvgPool2d: 2-2            [-1, 512, 1, 1]           --\n",
      "==========================================================================================\n",
      "Total params: 549,435\n",
      "Trainable params: 549,435\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.95\n",
      "Forward/backward pass size (MB): 30.52\n",
      "Params size (MB): 2.10\n",
      "Estimated Total Size (MB): 33.57\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------------------------------------\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─ResNetEncoder: 1-1                     [-1, 512, 32, 32]         --\n",
       "|    └─Sequential: 2-1                   [-1, 32, 125, 125]        --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 32, 250, 250]        1,568\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 32, 250, 250]        64\n",
       "|    |    └─ReLU: 3-3                    [-1, 32, 250, 250]        --\n",
       "|    |    └─MaxPool2d: 3-4               [-1, 32, 125, 125]        --\n",
       "├─ResNetDecoder: 1-2                     [-1, 1]                   --\n",
       "|    └─AdaptiveAvgPool2d: 2-2            [-1, 512, 1, 1]           --\n",
       "==========================================================================================\n",
       "Total params: 549,435\n",
       "Trainable params: 549,435\n",
       "Non-trainable params: 0\n",
       "------------------------------------------------------------------------------------------\n",
       "Input size (MB): 0.95\n",
       "Forward/backward pass size (MB): 30.52\n",
       "Params size (MB): 2.10\n",
       "Estimated Total Size (MB): 33.57\n",
       "------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1,500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dta_x[:,:,568:768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dta_y[568:768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((-1, 500, 700)).astype(np.float32)\n",
    "Y = Y.reshape((-1, 1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 500, 700)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((180, 500, 700), (180, 1)), ((20, 500, 700), (20, 1)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_X.shape, train_Y.shape), (val_X.shape, val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(-1, 1, 500, 700)\n",
    "train_X = torch.from_numpy(train_X)\n",
    "\n",
    "train_Y = train_Y.astype(int)\n",
    "train_Y = torch.from_numpy(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X =  val_X.reshape(-1, 1, 500, 700)\n",
    "val_X = torch.from_numpy(val_X)\n",
    "\n",
    "val_Y = val_Y.astype(int)\n",
    "val_Y = torch.from_numpy(val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res_conv1(1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # dataset\n",
    "    x_train, y_train = Variable(train_X), Variable(train_Y)\n",
    "    x_val, y_val = Variable(val_X), Variable(val_Y)\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output_train = model(x_train)\n",
    "    output_val = model(x_val)\n",
    "    \n",
    "    loss_train = criterion(output_train, y_train.type(torch.float))\n",
    "    loss_val = criterion(output_val, y_val.type(torch.float))\n",
    "    \n",
    "    train_losses.append(loss_train)\n",
    "    val_losses.append(loss_val)\n",
    "    \n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    \n",
    "    print('Epoch: ', epochs+1, '\\t', 'train loss: ', loss_train, '\\t', 'val loss: ', loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = Variable(train_X), Variable(train_Y)\n",
    "x_val, y_val = Variable(val_X), Variable(val_Y)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_val = model(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = criterion(output_train, y_train.type(torch.float))\n",
    "loss_val = criterion(output_val, y_val.type(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 \t train loss:  tensor(0.6873, grad_fn=<BinaryCrossEntropyBackward>) \t val loss:  tensor(0.6708, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epochs in range(n_epochs):\n",
    "    train(epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
