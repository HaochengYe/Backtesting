{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = datetime(1980, 1, 1)\n",
    "END = datetime(2020, 4, 23)\n",
    "msft = yf.Ticker(\"MSFT\")\n",
    "data = msft.history(start=START, end=END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lag_close'] = data['Close'].shift(1)\n",
    "data['Indicator'] = np.where(data['Close'] > data['lag_close'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dta = data.iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dta_to_candlestick(data):\n",
    "    l = len(data)\n",
    "    # Make candlestick picture\n",
    "    layout = go.Layout(xaxis=dict(ticks='',\n",
    "                                  showgrid=False,\n",
    "                                  showticklabels=False,\n",
    "                                  rangeslider=dict(visible=False)),\n",
    "                       yaxis=dict(ticks='',\n",
    "                                  showgrid=False,\n",
    "                                  showticklabels=False),\n",
    "                       #width=500,\n",
    "                       #height=500,\n",
    "                       paper_bgcolor='rgba(0,0,0,0)',\n",
    "                       plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig = go.Figure(data=[go.Candlestick(x=np.linspace(1,l,l),\n",
    "                                         open=data.Open,\n",
    "                                         high=data.High,\n",
    "                                         low=data.Low,\n",
    "                                         close=data.Close)],\n",
    "                    layout=layout)\n",
    "    fig.write_image(\"images/fig.png\")\n",
    "\n",
    "    # Convert to numpy array\n",
    "    im = Image.open('images/fig.png')\n",
    "    data = np.asarray(im)\n",
    "\n",
    "    # Return the first channel of the image\n",
    "    return data[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_dta = dta_to_candlestick(sub_dta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(30, data.shape[0]):\n",
    "    sub_dta = data.iloc[i - 30:i]\n",
    "\n",
    "    y_i = data.iloc[i]['Indicator']\n",
    "    x_i = dta_to_candlestick(sub_dta)\n",
    "\n",
    "    y.append(y_i)\n",
    "    x.append(x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_x = np.stack(x, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 700, 8568)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('data.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset_1\": shape (500, 700, 8568), type \"|u1\">"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.create_dataset('dataset_1', data=dta_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('MSFT_x.npy', dta_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('MSFT_test', a=dta_x, b=np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load('MSFT_test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_x = loaded['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 700, 8568)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Machine Learning Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import torch\n",
    "from torch.nn import Linear, ReLU, Conv1d, Conv2d, Flatten, Sequential, CrossEntropyLoss, MSELoss, MaxPool1d, MaxPool2d, Dropout, BatchNorm1d, BatchNorm2d\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding = (self.kernel_size[0] // 2, self.kernel_size[1] // 2)\n",
    "        \n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "conv = conv3x3(in_channels=32, out_channels=64)\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_func(activation):\n",
    "    return nn.ModuleDict([\n",
    "        ['relu', nn.ReLU(inplace=True)],\n",
    "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
    "        ['selu', nn.SELU(inplace=True)],\n",
    "        ['none', nn.Identity()]\n",
    "    ])[activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
    "        self.blocks = nn.Identity()\n",
    "        self.activate = activation_func(activation)\n",
    "        self.shortcut = nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        x = self.activate(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1, stride=self.downsampling, bias=False),\n",
    "            nn.BatchNorm2d(self.expanded_channels)) if self.should_apply_shortcut else None\n",
    "    \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetResidualBlock(\n",
       "  (blocks): Identity()\n",
       "  (activate): ReLU(inplace=True)\n",
       "  (shortcut): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNetResidualBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs),\n",
    "                        nn.BatchNorm2d(out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 10, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.ones((1,32, 10, 10))\n",
    "\n",
    "block = ResNetBasicBlock(32, 64)\n",
    "block(dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetBasicBlock(\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (activate): ReLU(inplace=True)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBottleNeckBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels, out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels * block.expansion,\n",
    "                   out_channels, downsampling=1, *args, **kwargs) for _ in range(n-1)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 24, 24])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.ones((1,64, 48,48))\n",
    "\n",
    "layer = ResNetLayer(64, 128, block=ResNetBottleNeckBlock, n=1)\n",
    "layer(dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[1, 1, 1, 1], activation='relu',\n",
    "                 block=ResNetBottleNeckBlock, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block_sizes = blocks_sizes\n",
    "\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.block_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.block_sizes[0]),\n",
    "            activation_func(activation),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, block=block, *args,\n",
    "                        **kwargs),\n",
    "            *[ResNetLayer(in_channels * block.expansion, out_channels, n=n, activation=activation, block=block, *args,\n",
    "                          **kwargs)\n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])\n",
    "              ]\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetDecoder(nn.Module):\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.decoder = nn.ModuleList([\n",
    "            nn.Linear(in_features, 500),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 100),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 25),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for block in self.decoder:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
    "        self.decoder = ResNetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_conv1(in_channels, n_classes, block=ResNetBottleNeckBlock, *args, **kwargs):\n",
    "    return ResNet(in_channels, n_classes, block=block, deepths=[1,1,1,1], *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res_conv1(3, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ResNetEncoder: 1-1                     [-1, 2048, 2, 2]          --\n",
      "|    └─Sequential: 2-1                   [-1, 64, 16, 16]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 32, 32]          9,408\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 32, 32]          128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 32, 32]          --\n",
      "|    |    └─MaxPool2d: 3-4               [-1, 64, 16, 16]          --\n",
      "├─ResNetDecoder: 1-2                     [-1, 25]                  --\n",
      "|    └─AdaptiveAvgPool2d: 2-2            [-1, 2048, 1, 1]          --\n",
      "==========================================================================================\n",
      "Total params: 9,093,061\n",
      "Trainable params: 9,093,061\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.00\n",
      "Params size (MB): 34.69\n",
      "Estimated Total Size (MB): 35.74\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------------------------------------\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─ResNetEncoder: 1-1                     [-1, 2048, 2, 2]          --\n",
       "|    └─Sequential: 2-1                   [-1, 64, 16, 16]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 32, 32]          9,408\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 32, 32]          128\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 32, 32]          --\n",
       "|    |    └─MaxPool2d: 3-4               [-1, 64, 16, 16]          --\n",
       "├─ResNetDecoder: 1-2                     [-1, 25]                  --\n",
       "|    └─AdaptiveAvgPool2d: 2-2            [-1, 2048, 1, 1]          --\n",
       "==========================================================================================\n",
       "Total params: 9,093,061\n",
       "Trainable params: 9,093,061\n",
       "Non-trainable params: 0\n",
       "------------------------------------------------------------------------------------------\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 1.00\n",
       "Params size (MB): 34.69\n",
       "Estimated Total Size (MB): 35.74\n",
       "------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.cuda(), (3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('C:\\\\Users\\\\Andyy\\\\Documents\\\\C_x.npy')\n",
    "Y = np.load('C:\\\\Users\\\\Andyy\\\\Documents\\\\C_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0\n",
    "Y = Y / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((-1, 500, 700))\n",
    "Y = X.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[:8000,:,:]\n",
    "train_Y = Y[:8000,:]\n",
    "test_X = X[8000:,:,:]\n",
    "test_Y = Y[8000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X.shape, train_Y.shape), (val_X.shape, val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
