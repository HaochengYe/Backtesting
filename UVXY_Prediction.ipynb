{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = datetime(1990,1,1)\n",
    "END = datetime(2020,6,5)\n",
    "\n",
    "UVXY = yf.Ticker('UVXY')\n",
    "hist = UVXY.history(start=START, end=END)\n",
    "hist.drop(['Volume', 'Dividends', 'Stock Splits'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix, :-1], sequence[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                    Open          High           Low         Close       RET  \\\nDate                                                                           \n2011-10-05  1.974600e+08  1.989000e+08  1.813800e+08  1.813800e+08 -0.118659   \n2011-10-06  1.811400e+08  1.878000e+08  1.740000e+08  1.740000e+08 -0.040688   \n2011-10-07  1.705800e+08  1.857600e+08  1.684800e+08  1.765200e+08  0.014483   \n2011-10-10  1.654800e+08  1.656000e+08  1.559400e+08  1.559400e+08 -0.116587   \n2011-10-11  1.570200e+08  1.572600e+08  1.491000e+08  1.506000e+08 -0.034244   \n...                  ...           ...           ...           ...       ...   \n2020-05-15  4.358000e+01  4.461000e+01  3.919000e+01  3.923000e+01 -0.037301   \n2020-05-18  3.529000e+01  3.643000e+01  3.466000e+01  3.544000e+01 -0.096610   \n2020-05-19  3.565000e+01  3.817000e+01  3.449000e+01  3.800000e+01  0.072235   \n2020-05-20  3.539000e+01  3.656000e+01  3.435000e+01  3.450000e+01 -0.092105   \n2020-05-21  3.454000e+01  3.692000e+01  3.383000e+01  3.571000e+01  0.035072   \n\n                   y  y_binary  \nDate                            \n2011-10-05 -0.405426       0.0  \n2011-10-06 -0.175707       0.0  \n2011-10-07 -0.133360       0.0  \n2011-10-10 -0.249292       0.0  \n2011-10-11 -0.254364       0.0  \n...              ...       ...  \n2020-05-15 -0.176722       0.0  \n2020-05-18 -0.131081       0.0  \n2020-05-19 -0.074649       0.0  \n2020-05-20 -0.211211       0.0  \n2020-05-21 -0.132921       0.0  \n\n[2171 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>RET</th>\n      <th>y</th>\n      <th>y_binary</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2011-10-05</td>\n      <td>1.974600e+08</td>\n      <td>1.989000e+08</td>\n      <td>1.813800e+08</td>\n      <td>1.813800e+08</td>\n      <td>-0.118659</td>\n      <td>-0.405426</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2011-10-06</td>\n      <td>1.811400e+08</td>\n      <td>1.878000e+08</td>\n      <td>1.740000e+08</td>\n      <td>1.740000e+08</td>\n      <td>-0.040688</td>\n      <td>-0.175707</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2011-10-07</td>\n      <td>1.705800e+08</td>\n      <td>1.857600e+08</td>\n      <td>1.684800e+08</td>\n      <td>1.765200e+08</td>\n      <td>0.014483</td>\n      <td>-0.133360</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2011-10-10</td>\n      <td>1.654800e+08</td>\n      <td>1.656000e+08</td>\n      <td>1.559400e+08</td>\n      <td>1.559400e+08</td>\n      <td>-0.116587</td>\n      <td>-0.249292</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2011-10-11</td>\n      <td>1.570200e+08</td>\n      <td>1.572600e+08</td>\n      <td>1.491000e+08</td>\n      <td>1.506000e+08</td>\n      <td>-0.034244</td>\n      <td>-0.254364</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>2020-05-15</td>\n      <td>4.358000e+01</td>\n      <td>4.461000e+01</td>\n      <td>3.919000e+01</td>\n      <td>3.923000e+01</td>\n      <td>-0.037301</td>\n      <td>-0.176722</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2020-05-18</td>\n      <td>3.529000e+01</td>\n      <td>3.643000e+01</td>\n      <td>3.466000e+01</td>\n      <td>3.544000e+01</td>\n      <td>-0.096610</td>\n      <td>-0.131081</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2020-05-19</td>\n      <td>3.565000e+01</td>\n      <td>3.817000e+01</td>\n      <td>3.449000e+01</td>\n      <td>3.800000e+01</td>\n      <td>0.072235</td>\n      <td>-0.074649</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2020-05-20</td>\n      <td>3.539000e+01</td>\n      <td>3.656000e+01</td>\n      <td>3.435000e+01</td>\n      <td>3.450000e+01</td>\n      <td>-0.092105</td>\n      <td>-0.211211</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2020-05-21</td>\n      <td>3.454000e+01</td>\n      <td>3.692000e+01</td>\n      <td>3.383000e+01</td>\n      <td>3.571000e+01</td>\n      <td>0.035072</td>\n      <td>-0.132921</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2171 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "hist['RET'] = hist['Close'].pct_change()\n",
    "hist.dropna(inplace=True)\n",
    "hist['y'] = hist['RET'].rolling(10).sum()\n",
    "hist['y_binary'] = (hist['y'] > 0).astype(int)\n",
    "hist['y'] = hist['y'].shift(-9)\n",
    "hist['y_binary'] = hist['y_binary'].shift(-9)\n",
    "hist.dropna(inplace=True)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq1 = np.array(hist['Open'].values.reshape(-1,1))\n",
    "in_seq2 = np.array(hist['High'].values.reshape(-1,1))\n",
    "in_seq3 = np.array(hist['Low'].values.reshape(-1,1))\n",
    "in_seq4 = np.array(hist['Close'].values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_seq = np.array(hist['y'].values.reshape(-1,1))\n",
    "out_seq_bin = np.array(hist['y_binary'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.hstack((in_seq1, in_seq2, in_seq3, in_seq4, out_seq))\n",
    "dataset_binary = np.hstack((in_seq1, in_seq2, in_seq3, in_seq4, out_seq_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MV_LSTM(nn.Module):\n",
    "    def __init__(self, n_features, seq_length, hidden_dim=20, num_layers=1):\n",
    "        super(MV_LSTM, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.seq_length = seq_length\n",
    "        self.n_hidden = hidden_dim\n",
    "        self.n_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.n_features,\n",
    "                            hidden_size=self.n_hidden,\n",
    "                            num_layers=self.n_layers,\n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(self.n_hidden*self.seq_length, 1)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden_state = torch.zeros(self.n_layers, batch_size, self.n_hidden)\n",
    "        cell_state = torch.zeros(self.n_layers, batch_size, self.n_hidden)\n",
    "        self.hidden = (hidden_state, cell_state)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        x = lstm_out.contiguous().view(batch_size, -1)\n",
    "        return self.linear(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MV_LSTM(\n  (lstm): LSTM(4, 20, batch_first=True)\n  (linear): Linear(in_features=200, out_features=1, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "MV_LSTM(4, 10, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1713, 30, 4)(429, 30, 4)\n"
    }
   ],
   "source": [
    "n_features = 4\n",
    "n_timesteps = 30\n",
    "\n",
    "X, y = split_sequence(dataset, n_timesteps)\n",
    "train_X, train_y, test_x, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_net = MV_LSTM(n_features, n_timesteps)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mv_net.parameters(), lr=1e-3)\n",
    "\n",
    "train_episides = 500\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "step:0loss:0.008446290157735348\nstep:1loss:0.048511676490306854\nstep:2loss:0.09100346267223358\nstep:3loss:0.008460832759737968\nstep:4loss:0.030830413103103638\nstep:5loss:0.009046810679137707\nstep:6loss:0.03293280303478241\nstep:7loss:0.0054622734896838665\nstep:8loss:0.049574293196201324\nstep:9loss:0.017918260768055916\nstep:10loss:0.01324972789734602\nstep:11loss:0.06455705314874649\nstep:12loss:0.006266560405492783\nstep:13loss:0.03446706756949425\nstep:14loss:0.016926784068346024\nstep:15loss:0.0057577816769480705\nstep:16loss:0.025672750547528267\nstep:17loss:0.03512733802199364\nstep:18loss:0.033383194357156754\nstep:19loss:0.0104270800948143\nstep:20loss:0.034760456532239914\nstep:21loss:0.02677108719944954\nstep:22loss:0.0056812032125890255\nstep:23loss:0.03612607344985008\nstep:24loss:0.043954525142908096\nstep:25loss:0.009082377888262272\nstep:26loss:0.03563332185149193\nstep:27loss:0.0068196398206055164\nstep:28loss:0.05103341117501259\nstep:29loss:0.018935034051537514\nstep:30loss:0.0129999415948987\nstep:31loss:0.037417829036712646\nstep:32loss:0.006615477614104748\nstep:33loss:0.048388831317424774\nstep:34loss:0.01511348132044077\nstep:35loss:0.021251363679766655\nstep:36loss:0.012357482686638832\nstep:37loss:0.01708395406603813\nstep:38loss:0.005660534370690584\nstep:39loss:0.051862429827451706\nstep:40loss:0.0406029038131237\nstep:41loss:0.00569829111918807\nstep:42loss:0.05308832600712776\nstep:43loss:0.005618161056190729\nstep:44loss:0.04155714437365532\nstep:45loss:0.007267285138368607\nstep:46loss:0.04127330705523491\nstep:47loss:0.011463248170912266\nstep:48loss:0.02745712734758854\nstep:49loss:0.005759290885180235\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-f4f883bd99e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mmv_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmv_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-f38985ef357c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 559\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mv_net.train()\n",
    "\n",
    "for t in range(train_episides):\n",
    "    for b in range(0, len(train_X), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        inpt = train_X[b:b+batch_size, :, :]\n",
    "        target = train_y[b:b+batch_size]\n",
    "\n",
    "        x_batch = torch.tensor(inpt, dtype=torch.float32)\n",
    "        y_batch = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "        mv_net.init_hidden(x_batch.size(0))\n",
    "        output = mv_net(x_batch)\n",
    "\n",
    "        loss_train = criterion(output.view(-1), y_batch)\n",
    "        loss_train.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    print(\"Step: () Train Loss: () Val Loss: ()\".format(t, round(loss_train.item(), 4), round(loss_val.item(), 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                    Open          High           Low         Close       RET  \\\nDate                                                                           \n2011-10-05  1.974600e+08  1.989000e+08  1.813800e+08  1.813800e+08 -0.118659   \n2011-10-06  1.811400e+08  1.878000e+08  1.740000e+08  1.740000e+08 -0.040688   \n2011-10-07  1.705800e+08  1.857600e+08  1.684800e+08  1.765200e+08  0.014483   \n2011-10-10  1.654800e+08  1.656000e+08  1.559400e+08  1.559400e+08 -0.116587   \n2011-10-11  1.570200e+08  1.572600e+08  1.491000e+08  1.506000e+08 -0.034244   \n...                  ...           ...           ...           ...       ...   \n2020-05-15  4.358000e+01  4.461000e+01  3.919000e+01  3.923000e+01 -0.037301   \n2020-05-18  3.529000e+01  3.643000e+01  3.466000e+01  3.544000e+01 -0.096610   \n2020-05-19  3.565000e+01  3.817000e+01  3.449000e+01  3.800000e+01  0.072235   \n2020-05-20  3.539000e+01  3.656000e+01  3.435000e+01  3.450000e+01 -0.092105   \n2020-05-21  3.454000e+01  3.692000e+01  3.383000e+01  3.571000e+01  0.035072   \n\n                   y  y_binary  \nDate                            \n2011-10-05 -0.405426       0.0  \n2011-10-06 -0.175707       0.0  \n2011-10-07 -0.133360       0.0  \n2011-10-10 -0.249292       0.0  \n2011-10-11 -0.254364       0.0  \n...              ...       ...  \n2020-05-15 -0.176722       0.0  \n2020-05-18 -0.131081       0.0  \n2020-05-19 -0.074649       0.0  \n2020-05-20 -0.211211       0.0  \n2020-05-21 -0.132921       0.0  \n\n[2171 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>RET</th>\n      <th>y</th>\n      <th>y_binary</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2011-10-05</td>\n      <td>1.974600e+08</td>\n      <td>1.989000e+08</td>\n      <td>1.813800e+08</td>\n      <td>1.813800e+08</td>\n      <td>-0.118659</td>\n      <td>-0.405426</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2011-10-06</td>\n      <td>1.811400e+08</td>\n      <td>1.878000e+08</td>\n      <td>1.740000e+08</td>\n      <td>1.740000e+08</td>\n      <td>-0.040688</td>\n      <td>-0.175707</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2011-10-07</td>\n      <td>1.705800e+08</td>\n      <td>1.857600e+08</td>\n      <td>1.684800e+08</td>\n      <td>1.765200e+08</td>\n      <td>0.014483</td>\n      <td>-0.133360</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2011-10-10</td>\n      <td>1.654800e+08</td>\n      <td>1.656000e+08</td>\n      <td>1.559400e+08</td>\n      <td>1.559400e+08</td>\n      <td>-0.116587</td>\n      <td>-0.249292</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2011-10-11</td>\n      <td>1.570200e+08</td>\n      <td>1.572600e+08</td>\n      <td>1.491000e+08</td>\n      <td>1.506000e+08</td>\n      <td>-0.034244</td>\n      <td>-0.254364</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>2020-05-15</td>\n      <td>4.358000e+01</td>\n      <td>4.461000e+01</td>\n      <td>3.919000e+01</td>\n      <td>3.923000e+01</td>\n      <td>-0.037301</td>\n      <td>-0.176722</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2020-05-18</td>\n      <td>3.529000e+01</td>\n      <td>3.643000e+01</td>\n      <td>3.466000e+01</td>\n      <td>3.544000e+01</td>\n      <td>-0.096610</td>\n      <td>-0.131081</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2020-05-19</td>\n      <td>3.565000e+01</td>\n      <td>3.817000e+01</td>\n      <td>3.449000e+01</td>\n      <td>3.800000e+01</td>\n      <td>0.072235</td>\n      <td>-0.074649</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2020-05-20</td>\n      <td>3.539000e+01</td>\n      <td>3.656000e+01</td>\n      <td>3.435000e+01</td>\n      <td>3.450000e+01</td>\n      <td>-0.092105</td>\n      <td>-0.211211</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2020-05-21</td>\n      <td>3.454000e+01</td>\n      <td>3.692000e+01</td>\n      <td>3.383000e+01</td>\n      <td>3.571000e+01</td>\n      <td>0.035072</td>\n      <td>-0.132921</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2171 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitcontinuumvirtualenv48009ba53764420baffbdb8297af855b",
   "display_name": "Python 3.7.4 64-bit ('Continuum': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}